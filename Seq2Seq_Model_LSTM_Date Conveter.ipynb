{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V9mxr_oKTuOb"
   },
   "source": [
    "### Date Conveter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Translating from one date format to another format (Standard format)\n",
    "- This comes under sequence to sequence modeling\n",
    "- Taking the input(Sequence) and converting the another format(Sequence)\n",
    "- Using RNN, we can solve problem\n",
    "- Using Embeedings\n",
    "- Using Encoder(Input Sequence) and Decoder (Output Sequence)\n",
    "- Model build on LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "V03GegDjohUA",
    "outputId": "0f5e0940-291c-4d68-f2c0-6395b0bef274"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import LSTM, Multiply\n",
    "from keras.layers import  Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import random\n",
    "from faker import Faker\n",
    "import babel\n",
    "from babel.dates import format_date\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.legacy_seq2seq as seq2seq\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEm9BnjNpPgU"
   },
   "outputs": [],
   "source": [
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "FORMATS = ['short',\n",
    "           'medium',\n",
    "           'long',\n",
    "           'full',\n",
    "           'd MMM YYY',\n",
    "           'd MMMM YYY',\n",
    "           'dd MMM YYY',\n",
    "           'd MMM, YYY',\n",
    "           'd MMMM, YYY',\n",
    "           'dd, MMM YYY',\n",
    "           'd MM YY',\n",
    "           'd MMMM YYY',\n",
    "           'MMMM d YYY',\n",
    "           'MMMM d, YYY',\n",
    "           'dd.MM.YY',\n",
    "           ]\n",
    "\n",
    "LOCALES = babel.localedata.locale_identifiers()\n",
    "LOCALES = [lang for lang in LOCALES if 'en' in str(lang)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BhHAvpQJpZeg"
   },
   "outputs": [],
   "source": [
    "#Genrating the fake data for the above mentinoed format\n",
    "def create_date():\n",
    "    dt = fake.date_object()\n",
    "    try:\n",
    "        human = format_date(dt,\n",
    "                            format=random.choice(FORMATS),\n",
    "                            locale=random.choice(LOCALES))\n",
    "\n",
    "        case_change = random.randint(0,3) # 1/2 chance of case change\n",
    "        if case_change == 1:\n",
    "            human = human.upper()\n",
    "        elif case_change == 2:\n",
    "            human = human.lower()\n",
    "\n",
    "        machine = dt.isoformat()\n",
    "    except AttributeError as e:\n",
    "        return None, None, None\n",
    "\n",
    "    return human, machine #, dt\n",
    "\n",
    "data = [create_date() for _ in range(50000)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-ASCnIJ9ppb_",
    "outputId": "5ad5fdf5-3209-43df-a590-ce7930098260"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('7 07 13', '2013-07-07'),\n",
       " ('30 JULY 1977', '1977-07-30'),\n",
       " ('Tuesday, 14 September 1971', '1971-09-14'),\n",
       " ('18 09 88', '1988-09-18'),\n",
       " ('31, Aug 1986', '1986-08-31')]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#See below what we are trying to do in this lesson. \n",
    "#We are taking dates of various formats and converting them into a standard date format\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s89k0j2cpt7f"
   },
   "outputs": [],
   "source": [
    "x = [x for x, y in data]\n",
    "y = [y for x, y in data]\n",
    "\n",
    "u_characters = set(' '.join(x)) # Unique Charctes in X\n",
    "char2numX = dict(zip(u_characters, range(len(u_characters)))) #Converting char to number for X\n",
    "\n",
    "u_characters = set(' '.join(y)) # Unique Charcters in Y\n",
    "char2numY = dict(zip(u_characters, range(len(u_characters)))) # Converting char to number for y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KeaLfnGZpxZB",
    "outputId": "5fa026fd-b039-41f9-c951-514e7a8c4989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>31, Aug 1986\n"
     ]
    }
   ],
   "source": [
    "#Pad all sequences that are shorter than the max lengnth of the sequence\n",
    "char2numX['<PAD>'] = len(char2numX)\n",
    "num2charX = dict(zip(char2numX.values(), char2numX.keys()))\n",
    "max_len = max([len(date) for date in x])\n",
    "\n",
    "x = [[char2numX['<PAD>']]*(max_len - len(date)) +[char2numX[x_] for x_ in date] for date in x]\n",
    "print(''.join([num2charX[x_] for x_ in x[4]]))\n",
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eqkWO8Fup2Rv",
    "outputId": "c1653bee-dbd5-4c60-eb1a-c0fdb26138ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<GO>1986-08-31\n"
     ]
    }
   ],
   "source": [
    "#The output here is always fixed length\n",
    "char2numY['<GO>'] = len(char2numY)\n",
    "num2charY = dict(zip(char2numY.values(), char2numY.keys()))\n",
    "\n",
    "y = [[char2numY['<GO>']] + [char2numY[y_] for y_ in date] for date in y]\n",
    "print(''.join([num2charY[y_] for y_ in y[4]]))\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4U7V6dMOp4nP"
   },
   "outputs": [],
   "source": [
    "x_seq_length = len(x[0])\n",
    "y_seq_length = len(y[0])- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E5MAvWpPp7Z_"
   },
   "outputs": [],
   "source": [
    "#Taking the entire dataset diving batches\n",
    "def batch_data(x, y, batch_size):\n",
    "    shuffle = np.random.permutation(len(x))\n",
    "    start = 0\n",
    "    x = x[shuffle]\n",
    "    y = y[shuffle]\n",
    "    while start + batch_size <= len(x):\n",
    "        yield x[start:start+batch_size], y[start:start+batch_size]\n",
    "        start += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNbn_UITx785"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 344
    },
    "colab_type": "code",
    "id": "xB5dpwqJp_oO",
    "outputId": "72831dfd-80f5-4958-90f0-6d73cf1e69e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-14-64a8b236dbdc>:21: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-14-64a8b236dbdc>:22: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:735: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:739: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1866: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "batch_size = 128\n",
    "nodes = 32\n",
    "embed_size = 10\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# Tensor where we will feed the data into graph\n",
    "inputs = tf.placeholder(tf.int32, (None, x_seq_length), 'inputs') # X\n",
    "outputs = tf.placeholder(tf.int32, (None, None), 'output') #\n",
    "targets = tf.placeholder(tf.int32, (None, None), 'targets')\n",
    "\n",
    "# Embedding layers\n",
    "input_embedding = tf.Variable(tf.random_uniform((len(char2numX), embed_size), -1.0, 1.0), name='enc_embedding')\n",
    "output_embedding = tf.Variable(tf.random_uniform((len(char2numY), embed_size), -1.0, 1.0), name='dec_embedding')\n",
    "date_input_embed = tf.nn.embedding_lookup(input_embedding, inputs)\n",
    "date_output_embed = tf.nn.embedding_lookup(output_embedding, outputs)\n",
    "\n",
    "with tf.variable_scope(\"encoding\") as encoding_scope:\n",
    "    lstm_enc = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    _, last_state = tf.nn.dynamic_rnn(lstm_enc, inputs=date_input_embed, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "    lstm_dec = tf.contrib.rnn.BasicLSTMCell(nodes)\n",
    "    dec_outputs, _ = tf.nn.dynamic_rnn(lstm_dec, inputs=date_output_embed, initial_state=last_state)\n",
    "#connect outputs to \n",
    "logits = tf.contrib.layers.fully_connected(dec_outputs, num_outputs=len(char2numY), activation_fn=None) \n",
    "with tf.name_scope(\"optimization\"):\n",
    "    # Loss function\n",
    "    loss = tf.contrib.seq2seq.sequence_loss(logits, targets, tf.ones([batch_size, y_seq_length]))\n",
    "    # Optimizer\n",
    "    optimizer = tf.train.RMSPropOptimizer(1e-3).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a9MFGlFoqNej"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "Fu_RCn7nqSB_",
    "outputId": "11fcddcb-cbf2-494b-da10-357d329b65de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Loss:  1.352 Accuracy: 0.5523 Epoch duration:  5.775s\n",
      "Epoch   1 Loss:  0.808 Accuracy: 0.7141 Epoch duration:  5.351s\n",
      "Epoch   2 Loss:  0.671 Accuracy: 0.7672 Epoch duration:  5.213s\n",
      "Epoch   3 Loss:  0.532 Accuracy: 0.8211 Epoch duration:  5.224s\n",
      "Epoch   4 Loss:  0.473 Accuracy: 0.8391 Epoch duration:  5.162s\n",
      "Epoch   5 Loss:  0.386 Accuracy: 0.8625 Epoch duration:  5.281s\n",
      "Epoch   6 Loss:  0.376 Accuracy: 0.8656 Epoch duration:  5.238s\n",
      "Epoch   7 Loss:  0.303 Accuracy: 0.8875 Epoch duration:  5.217s\n",
      "Epoch   8 Loss:  0.248 Accuracy: 0.9148 Epoch duration:  5.270s\n",
      "Epoch   9 Loss:  0.205 Accuracy: 0.9297 Epoch duration:  5.330s\n"
     ]
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "epochs = 10\n",
    "for epoch_i in range(epochs):\n",
    "    start_time = time.time()\n",
    "    for batch_i, (source_batch, target_batch) in enumerate(batch_data(X_train, y_train, batch_size)):\n",
    "        _, batch_loss, batch_logits = sess.run([optimizer, loss, logits],\n",
    "            feed_dict = {inputs: source_batch,\n",
    "             outputs: target_batch[:, :-1],\n",
    "             targets: target_batch[:, 1:]})\n",
    "    accuracy = np.mean(batch_logits.argmax(axis=-1) == target_batch[:,1:])\n",
    "    print('Epoch {:3} Loss: {:>6.3f} Accuracy: {:>6.4f} Epoch duration: {:>6.3f}s'.format(epoch_i, batch_loss, accuracy, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eq3AE7jVqXWu",
    "outputId": "750c2b4f-4f75-42b0-c748-69334a6ce7f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is:  0.914\n"
     ]
    }
   ],
   "source": [
    "source_batch, target_batch = next(batch_data(X_test, y_test, batch_size))\n",
    "\n",
    "dec_input = np.zeros((len(source_batch), 1)) + char2numY['<GO>']\n",
    "for i in range(y_seq_length):\n",
    "    batch_logits = sess.run(logits,\n",
    "                feed_dict = {inputs: source_batch,\n",
    "                 outputs: dec_input})\n",
    "    prediction = batch_logits[:,-1].argmax(axis=-1)\n",
    "    dec_input = np.hstack([dec_input, prediction[:,None]])\n",
    "    \n",
    "print('Accuracy on test set is: {:>6.3f}'.format(np.mean(dec_input == target_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "GFByNHEIquty",
    "outputId": "f5134ddd-66cc-4e19-a5c9-f504efc1a4c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 april 2015 => 2015-09-28\n",
      "3 JUL 1995 => 1995-07-30\n",
      "16 MAY 2017 => 2017-01-04\n",
      "17 July 1989 => 1989-07-17\n",
      "march 22, 1970 => 1970-02-22\n"
     ]
    }
   ],
   "source": [
    "num_preds = 5\n",
    "source_chars = [[num2charX[l] for l in sent if num2charX[l]!=\"<PAD>\"] for sent in source_batch[:num_preds]]\n",
    "dest_chars = [[num2charY[l] for l in sent] for sent in dec_input[:num_preds, 1:]]\n",
    "\n",
    "for date_in, date_out in zip(source_chars, dest_chars):\n",
    "    print(''.join(date_in)+' => '+''.join(date_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L54RNdndq0bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
